{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('HalfCheetahBulletEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(6,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  26\n",
      "Size of Action Space ->  6\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    }
   ],
   "source": [
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity, batch_size):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "\n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch,):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            \n",
    "            \n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions], training=True)\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor():\n",
    "    last_init=tf.random_uniform_initializer(minval=-0.003,maxval=0.003)\n",
    "    i=layers.Input(shape=(num_states))\n",
    "    x=layers.Dense(128,activation='relu',autocast=False)(i)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(num_actions,activation='tanh',kernel_initializer=last_init)(x)\n",
    "    x=x*upper_bound\n",
    "    model=tf.keras.Model(i,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor=get_actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         [(None, 26)]              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 128)               3456      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_mul_3 (TensorFlo [(None, 6)]               0         \n",
      "=================================================================\n",
      "Total params: 103,814\n",
      "Trainable params: 103,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic():\n",
    "    state_input=layers.Input(shape=(num_states))\n",
    "    state_output=layers.Dense(16,activation='relu',autocast=False)(state_input)\n",
    "    state_output=layers.Dense(32,activation='relu')(state_output)\n",
    "    \n",
    "    action_input=layers.Input(shape=(num_actions))\n",
    "    action_output=layers.Dense(16,activation='relu')(action_input)\n",
    "    action_output=layers.Dense(32,activation='relu')(action_output)\n",
    "\n",
    "    concat=layers.Concatenate()([state_output,action_output])\n",
    "    x=layers.Dense(256,activation='relu')(concat)\n",
    "    \n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(1,activation='linear')(x)\n",
    "    model=tf.keras.Model([state_input,action_input],x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return np.squeeze(legal_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.1\n",
    "ou_noise = OUActionNoise(mean=np.zeros(6), std_deviation=float(std_dev) * np.ones(6))\n",
    "\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "\n",
    "critic_lr = 0.0003\n",
    "actor_lr = 0.0003\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 500\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "tau = 0.50\n",
    "\n",
    "buffer = Buffer(100000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1533.163391230902\n",
      "Episode * 1 * Avg Reward is ==> -1598.583439606922\n",
      "Episode * 2 * Avg Reward is ==> -1614.1833402970212\n",
      "Episode * 3 * Avg Reward is ==> -1620.739791412544\n",
      "Episode * 4 * Avg Reward is ==> -1625.7942815372376\n",
      "Episode * 5 * Avg Reward is ==> -1629.9456047283556\n",
      "Episode * 6 * Avg Reward is ==> -1633.3086818687782\n",
      "Episode * 7 * Avg Reward is ==> -1636.9021217430425\n",
      "Episode * 8 * Avg Reward is ==> -1639.6569842472816\n",
      "Episode * 9 * Avg Reward is ==> -1642.1359215843331\n",
      "Episode * 10 * Avg Reward is ==> -1644.5660058659464\n",
      "Episode * 11 * Avg Reward is ==> -1645.9927819970696\n",
      "Episode * 12 * Avg Reward is ==> -1647.4100343789528\n",
      "Episode * 13 * Avg Reward is ==> -1648.9864960227512\n",
      "Episode * 14 * Avg Reward is ==> -1649.554519823841\n",
      "Episode * 15 * Avg Reward is ==> -1650.010445761234\n",
      "Episode * 16 * Avg Reward is ==> -1650.4474243978752\n",
      "Episode * 17 * Avg Reward is ==> -1651.4289643071318\n",
      "Episode * 18 * Avg Reward is ==> -1651.8247468854806\n",
      "Episode * 19 * Avg Reward is ==> -1651.8469627220777\n",
      "Episode * 20 * Avg Reward is ==> -1652.3254745100573\n",
      "Episode * 21 * Avg Reward is ==> -1652.2630918629582\n",
      "Episode * 22 * Avg Reward is ==> -1651.6568457910648\n",
      "Episode * 23 * Avg Reward is ==> -1652.0151435914497\n",
      "Episode * 24 * Avg Reward is ==> -1652.7391004854744\n",
      "Episode * 25 * Avg Reward is ==> -1652.5970314101296\n",
      "Episode * 26 * Avg Reward is ==> -1652.7308588069181\n",
      "Episode * 27 * Avg Reward is ==> -1652.9888724081811\n",
      "Episode * 28 * Avg Reward is ==> -1652.9444523286115\n",
      "Episode * 29 * Avg Reward is ==> -1653.2791730688027\n",
      "Episode * 30 * Avg Reward is ==> -1653.6474473371472\n",
      "Episode * 31 * Avg Reward is ==> -1653.9990502592877\n",
      "Episode * 32 * Avg Reward is ==> -1654.585443905718\n",
      "Episode * 33 * Avg Reward is ==> -1654.8058133159348\n",
      "Episode * 34 * Avg Reward is ==> -1654.9915365763754\n",
      "Episode * 35 * Avg Reward is ==> -1655.2801210148668\n",
      "Episode * 36 * Avg Reward is ==> -1655.2590018083317\n",
      "Episode * 37 * Avg Reward is ==> -1655.3252679548725\n",
      "Episode * 38 * Avg Reward is ==> -1655.5996904588858\n",
      "Episode * 39 * Avg Reward is ==> -1655.901527615272\n",
      "Episode * 40 * Avg Reward is ==> -1656.5242906949727\n",
      "Episode * 41 * Avg Reward is ==> -1656.7466289935805\n",
      "Episode * 42 * Avg Reward is ==> -1657.0964646928664\n",
      "Episode * 43 * Avg Reward is ==> -1657.0599988642775\n",
      "Episode * 44 * Avg Reward is ==> -1657.056534611511\n",
      "Episode * 45 * Avg Reward is ==> -1656.9557942918302\n",
      "Episode * 46 * Avg Reward is ==> -1656.0718870520172\n",
      "Episode * 47 * Avg Reward is ==> -1656.1566028442842\n",
      "Episode * 48 * Avg Reward is ==> -1656.1803251277342\n",
      "Episode * 49 * Avg Reward is ==> -1656.0420132313718\n",
      "Episode * 50 * Avg Reward is ==> -1658.3864622802053\n",
      "Episode * 51 * Avg Reward is ==> -1658.1233310783844\n",
      "Episode * 52 * Avg Reward is ==> -1658.369928202752\n",
      "Episode * 53 * Avg Reward is ==> -1659.0988523013086\n",
      "Episode * 54 * Avg Reward is ==> -1659.524028159812\n",
      "Episode * 55 * Avg Reward is ==> -1659.4394902890592\n",
      "Episode * 56 * Avg Reward is ==> -1659.4497353954619\n",
      "Episode * 57 * Avg Reward is ==> -1659.2503996991065\n",
      "Episode * 58 * Avg Reward is ==> -1659.3223273775334\n",
      "Episode * 59 * Avg Reward is ==> -1659.1554541213739\n",
      "Episode * 60 * Avg Reward is ==> -1658.9043222908047\n",
      "Episode * 61 * Avg Reward is ==> -1658.7203982767023\n",
      "Episode * 62 * Avg Reward is ==> -1658.4029863451765\n",
      "Episode * 63 * Avg Reward is ==> -1658.2823566242203\n",
      "Episode * 64 * Avg Reward is ==> -1658.4596342579441\n",
      "Episode * 65 * Avg Reward is ==> -1658.7756626712091\n",
      "Episode * 66 * Avg Reward is ==> -1658.838083716065\n",
      "Episode * 67 * Avg Reward is ==> -1658.6605829840075\n",
      "Episode * 68 * Avg Reward is ==> -1658.8332589765062\n",
      "Episode * 69 * Avg Reward is ==> -1659.318741318889\n",
      "Episode * 70 * Avg Reward is ==> -1659.4109869684135\n",
      "Episode * 71 * Avg Reward is ==> -1659.5941128182112\n",
      "Episode * 72 * Avg Reward is ==> -1660.2191216747542\n",
      "Episode * 73 * Avg Reward is ==> -1660.1125650953427\n",
      "Episode * 74 * Avg Reward is ==> -1659.9315244234592\n",
      "Episode * 75 * Avg Reward is ==> -1660.123145071064\n",
      "Episode * 76 * Avg Reward is ==> -1659.8095218778878\n",
      "Episode * 77 * Avg Reward is ==> -1659.707357062519\n",
      "Episode * 78 * Avg Reward is ==> -1659.7773364308714\n",
      "Episode * 79 * Avg Reward is ==> -1659.7069586607786\n",
      "Episode * 80 * Avg Reward is ==> -1659.5708872505857\n",
      "Episode * 81 * Avg Reward is ==> -1659.7376834029265\n",
      "Episode * 82 * Avg Reward is ==> -1659.70467728591\n",
      "Episode * 83 * Avg Reward is ==> -1659.656645913988\n",
      "Episode * 84 * Avg Reward is ==> -1659.7204553890122\n",
      "Episode * 85 * Avg Reward is ==> -1659.421874215817\n",
      "Episode * 86 * Avg Reward is ==> -1659.1335886015527\n",
      "Episode * 87 * Avg Reward is ==> -1658.9400961604072\n",
      "Episode * 88 * Avg Reward is ==> -1659.1365858628217\n",
      "Episode * 89 * Avg Reward is ==> -1659.0823023872074\n",
      "Episode * 90 * Avg Reward is ==> -1658.6389775433968\n",
      "Episode * 91 * Avg Reward is ==> -1658.594361584479\n",
      "Episode * 92 * Avg Reward is ==> -1658.3341154803452\n",
      "Episode * 93 * Avg Reward is ==> -1658.2900048383558\n",
      "Episode * 94 * Avg Reward is ==> -1658.5370225127106\n",
      "Episode * 95 * Avg Reward is ==> -1658.870427674903\n",
      "Episode * 96 * Avg Reward is ==> -1659.62268047406\n",
      "Episode * 97 * Avg Reward is ==> -1659.8472728943518\n",
      "Episode * 98 * Avg Reward is ==> -1659.5889157705085\n",
      "Episode * 99 * Avg Reward is ==> -1659.7734698370314\n",
      "Episode * 100 * Avg Reward is ==> -1659.921023567067\n",
      "Episode * 101 * Avg Reward is ==> -1659.621443310281\n",
      "Episode * 102 * Avg Reward is ==> -1659.4831345358275\n",
      "Episode * 103 * Avg Reward is ==> -1659.0175952003503\n",
      "Episode * 104 * Avg Reward is ==> -1658.8063611412813\n",
      "Episode * 105 * Avg Reward is ==> -1658.967966896767\n",
      "Episode * 106 * Avg Reward is ==> -1658.9801615265542\n",
      "Episode * 107 * Avg Reward is ==> -1659.2838366495207\n",
      "Episode * 108 * Avg Reward is ==> -1659.2327036883153\n",
      "Episode * 109 * Avg Reward is ==> -1659.2474309550835\n",
      "Episode * 110 * Avg Reward is ==> -1659.3472123640743\n",
      "Episode * 111 * Avg Reward is ==> -1659.4475912858386\n",
      "Episode * 112 * Avg Reward is ==> -1659.7421143153117\n",
      "Episode * 113 * Avg Reward is ==> -1659.4853063847468\n",
      "Episode * 114 * Avg Reward is ==> -1658.950310981093\n",
      "Episode * 115 * Avg Reward is ==> -1658.4713705577542\n",
      "Episode * 116 * Avg Reward is ==> -1657.7916931786044\n",
      "Episode * 117 * Avg Reward is ==> -1657.422259142924\n",
      "Episode * 118 * Avg Reward is ==> -1657.4225366507546\n",
      "Episode * 119 * Avg Reward is ==> -1657.2807284299145\n",
      "Episode * 120 * Avg Reward is ==> -1657.2028921849412\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-4c661c0007d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtf_prev_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_prev_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mou_noise\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-540d7c8cbe59>\u001b[0m in \u001b[0;36mpolicy\u001b[1;34m(state, noise_object)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0msampled_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mactor_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnoise_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msampled_actions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msampled_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnoise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    715\u001b[0m     return self._run_internal_graph(\n\u001b[0;32m    716\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 717\u001b[1;33m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[0;32m    718\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    719\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m           \u001b[1;31m# Compute outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m           \u001b[0moutput_tensors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m           \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    820\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[0;32m    821\u001b[0m               self._compute_dtype):\n\u001b[1;32m--> 822\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1140\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msparse_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse_tensor_dense_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5603\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5604\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5605\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5606\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ep_reward_list = []\n",
    "\n",
    "avg_reward_list = []\n",
    "\n",
    "\n",
    "for ep in range(total_episodes):\n",
    "\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "    \n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state, action, reward, state))\n",
    "        episodic_reward += reward\n",
    "\n",
    "        buffer.learn()\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prev_state = state\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "    avg_reward = np.mean(ep_reward_list[-50:])\n",
    "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "\n",
    "\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
