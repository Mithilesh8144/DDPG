{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybullet_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('HalfCheetahBulletEnv-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(6,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  26\n",
      "Size of Action Space ->  6\n",
      "Max Value of Action ->  1.0\n",
      "Min Value of Action ->  -1.0\n"
     ]
    }
   ],
   "source": [
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity, batch_size):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "\n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch,):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            \n",
    "            \n",
    "            y = reward_batch + gamma * target_critic([next_state_batch, target_actions], training=True)\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "        \n",
    "\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor():\n",
    "    last_init=tf.random_uniform_initializer(minval=-0.003,maxval=0.003)\n",
    "    i=layers.Input(shape=(num_states))\n",
    "    x=layers.Dense(128,activation='relu',autocast=False)(i)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(num_actions,activation='tanh',kernel_initializer=last_init)(x)\n",
    "    x=x*upper_bound\n",
    "    model=tf.keras.Model(i,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor=get_actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 26)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               3456      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 6)                 1542      \n",
      "_________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowO [(None, 6)]               0         \n",
      "=================================================================\n",
      "Total params: 103,814\n",
      "Trainable params: 103,814\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic():\n",
    "    state_input=layers.Input(shape=(num_states))\n",
    "    state_output=layers.Dense(16,activation='relu',autocast=False)(state_input)\n",
    "    state_output=layers.Dense(32,activation='relu')(state_output)\n",
    "    \n",
    "    action_input=layers.Input(shape=(num_actions))\n",
    "    action_output=layers.Dense(16,activation='relu')(action_input)\n",
    "    action_output=layers.Dense(32,activation='relu')(action_output)\n",
    "\n",
    "    concat=layers.Concatenate()([state_output,action_output])\n",
    "    x=layers.Dense(256,activation='relu')(concat)\n",
    "    \n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(1,activation='linear')(x)\n",
    "    model=tf.keras.Model([state_input,action_input],x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return np.squeeze(legal_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.1\n",
    "ou_noise = OUActionNoise(mean=np.zeros(6), std_deviation=float(std_dev) * np.ones(6))\n",
    "\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "\n",
    "critic_lr = 0.0002\n",
    "actor_lr = 0.0002\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 500\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "tau = 0.995\n",
    "\n",
    "buffer = Buffer(100000, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1381.6350175389255\n",
      "Episode * 1 * Avg Reward is ==> -1369.0498420414178\n",
      "Episode * 2 * Avg Reward is ==> -1384.187334411766\n",
      "Episode * 3 * Avg Reward is ==> -1366.9713154108745\n",
      "Episode * 4 * Avg Reward is ==> -1407.1611918261399\n",
      "Episode * 5 * Avg Reward is ==> -1453.5677963171056\n",
      "Episode * 6 * Avg Reward is ==> -1488.2753844053163\n",
      "Episode * 7 * Avg Reward is ==> -1513.4806268046989\n",
      "Episode * 8 * Avg Reward is ==> -1534.8877947870074\n",
      "Episode * 9 * Avg Reward is ==> -1551.300632142507\n",
      "Episode * 10 * Avg Reward is ==> -1564.5376579706965\n",
      "Episode * 11 * Avg Reward is ==> -1575.0791719232247\n",
      "Episode * 12 * Avg Reward is ==> -1582.7712966936529\n",
      "Episode * 13 * Avg Reward is ==> -1590.2087743663737\n",
      "Episode * 14 * Avg Reward is ==> -1596.671402358212\n",
      "Episode * 15 * Avg Reward is ==> -1601.5444331981616\n",
      "Episode * 16 * Avg Reward is ==> -1607.3023194791188\n",
      "Episode * 17 * Avg Reward is ==> -1610.6673181831038\n",
      "Episode * 18 * Avg Reward is ==> -1614.1772029243286\n",
      "Episode * 19 * Avg Reward is ==> -1615.724148585066\n",
      "Episode * 20 * Avg Reward is ==> -1618.8676756695613\n",
      "Episode * 21 * Avg Reward is ==> -1621.6698894274516\n",
      "Episode * 22 * Avg Reward is ==> -1623.6983880089297\n",
      "Episode * 23 * Avg Reward is ==> -1626.4086583196122\n",
      "Episode * 24 * Avg Reward is ==> -1629.2409637814856\n",
      "Episode * 25 * Avg Reward is ==> -1631.7137662725193\n",
      "Episode * 26 * Avg Reward is ==> -1633.9317762849435\n",
      "Episode * 27 * Avg Reward is ==> -1635.3866171591592\n",
      "Episode * 28 * Avg Reward is ==> -1637.2289940061899\n",
      "Episode * 29 * Avg Reward is ==> -1638.93355606425\n",
      "Episode * 30 * Avg Reward is ==> -1639.8303990127122\n",
      "Episode * 31 * Avg Reward is ==> -1640.9954629943004\n",
      "Episode * 32 * Avg Reward is ==> -1640.1869432943504\n",
      "Episode * 33 * Avg Reward is ==> -1641.5969852215583\n",
      "Episode * 34 * Avg Reward is ==> -1642.6682136272234\n",
      "Episode * 35 * Avg Reward is ==> -1643.0806801428316\n",
      "Episode * 36 * Avg Reward is ==> -1643.87995752027\n",
      "Episode * 37 * Avg Reward is ==> -1644.9410844336899\n",
      "Episode * 38 * Avg Reward is ==> -1645.9461621264381\n",
      "Episode * 39 * Avg Reward is ==> -1647.0656674469124\n",
      "Episode * 40 * Avg Reward is ==> -1647.9650529921414\n",
      "Episode * 41 * Avg Reward is ==> -1648.6157702892783\n",
      "Episode * 42 * Avg Reward is ==> -1649.5438954974488\n",
      "Episode * 43 * Avg Reward is ==> -1650.607337892032\n",
      "Episode * 44 * Avg Reward is ==> -1651.6189265206376\n",
      "Episode * 45 * Avg Reward is ==> -1652.2691064802766\n",
      "Episode * 46 * Avg Reward is ==> -1653.1856445211367\n",
      "Episode * 47 * Avg Reward is ==> -1654.1184146305193\n",
      "Episode * 48 * Avg Reward is ==> -1654.5208723012727\n",
      "Episode * 49 * Avg Reward is ==> -1654.988534651061\n",
      "Episode * 50 * Avg Reward is ==> -1660.9096957077106\n",
      "Episode * 51 * Avg Reward is ==> -1667.4119501738342\n",
      "Episode * 52 * Avg Reward is ==> -1672.6502147803737\n",
      "Episode * 53 * Avg Reward is ==> -1679.8021554460408\n",
      "Episode * 54 * Avg Reward is ==> -1681.9156309666382\n",
      "Episode * 55 * Avg Reward is ==> -1681.8085594764593\n",
      "Episode * 56 * Avg Reward is ==> -1681.3385467368937\n",
      "Episode * 57 * Avg Reward is ==> -1680.8641334389167\n",
      "Episode * 58 * Avg Reward is ==> -1680.1424659314162\n",
      "Episode * 59 * Avg Reward is ==> -1679.7974735632608\n",
      "Episode * 60 * Avg Reward is ==> -1679.619654780653\n",
      "Episode * 61 * Avg Reward is ==> -1679.4506001013995\n",
      "Episode * 62 * Avg Reward is ==> -1679.5611368130296\n",
      "Episode * 63 * Avg Reward is ==> -1679.3950389308586\n",
      "Episode * 64 * Avg Reward is ==> -1679.3063446041588\n",
      "Episode * 65 * Avg Reward is ==> -1679.5656816547241\n",
      "Episode * 66 * Avg Reward is ==> -1678.9980591044257\n",
      "Episode * 67 * Avg Reward is ==> -1679.4142449022258\n",
      "Episode * 68 * Avg Reward is ==> -1679.6446785097205\n",
      "Episode * 69 * Avg Reward is ==> -1680.579549596724\n",
      "Episode * 70 * Avg Reward is ==> -1680.9055595248772\n",
      "Episode * 71 * Avg Reward is ==> -1680.8656878976221\n",
      "Episode * 72 * Avg Reward is ==> -1680.7963185823291\n",
      "Episode * 73 * Avg Reward is ==> -1680.7459630283347\n",
      "Episode * 74 * Avg Reward is ==> -1680.1762295265198\n",
      "Episode * 75 * Avg Reward is ==> -1679.8500611980746\n",
      "Episode * 76 * Avg Reward is ==> -1679.169261304357\n",
      "Episode * 77 * Avg Reward is ==> -1679.2757535885016\n",
      "Episode * 78 * Avg Reward is ==> -1679.129934528644\n",
      "Episode * 79 * Avg Reward is ==> -1677.9717784320057\n",
      "Episode * 80 * Avg Reward is ==> -1678.379160345355\n",
      "Episode * 81 * Avg Reward is ==> -1678.5176379599632\n",
      "Episode * 82 * Avg Reward is ==> -1679.988078034588\n",
      "Episode * 83 * Avg Reward is ==> -1679.8503784741051\n",
      "Episode * 84 * Avg Reward is ==> -1679.9080851572978\n",
      "Episode * 85 * Avg Reward is ==> -1680.1962930202674\n",
      "Episode * 86 * Avg Reward is ==> -1680.2193903678778\n",
      "Episode * 87 * Avg Reward is ==> -1680.142097789667\n",
      "Episode * 88 * Avg Reward is ==> -1680.1463132640065\n",
      "Episode * 89 * Avg Reward is ==> -1680.2493818652124\n",
      "Episode * 90 * Avg Reward is ==> -1680.2114219935895\n",
      "Episode * 91 * Avg Reward is ==> -1680.5372991200293\n",
      "Episode * 92 * Avg Reward is ==> -1680.3538140803744\n",
      "Episode * 93 * Avg Reward is ==> -1679.9802657879325\n",
      "Episode * 94 * Avg Reward is ==> -1679.6281774655001\n",
      "Episode * 95 * Avg Reward is ==> -1679.324445649862\n",
      "Episode * 96 * Avg Reward is ==> -1679.3668133505757\n",
      "Episode * 97 * Avg Reward is ==> -1679.2250025395413\n",
      "Episode * 98 * Avg Reward is ==> -1679.4064454607274\n",
      "Episode * 99 * Avg Reward is ==> -1679.4316697421784\n",
      "Episode * 100 * Avg Reward is ==> -1679.379027065766\n",
      "Episode * 101 * Avg Reward is ==> -1679.3150310078904\n",
      "Episode * 102 * Avg Reward is ==> -1679.6354544468998\n",
      "Episode * 103 * Avg Reward is ==> -1679.6049462250332\n",
      "Episode * 104 * Avg Reward is ==> -1680.0567509252587\n",
      "Episode * 105 * Avg Reward is ==> -1680.5008324351325\n",
      "Episode * 106 * Avg Reward is ==> -1681.0089235656785\n",
      "Episode * 107 * Avg Reward is ==> -1681.6851533462368\n",
      "Episode * 108 * Avg Reward is ==> -1682.2115254187281\n",
      "Episode * 109 * Avg Reward is ==> -1682.5259068386038\n",
      "Episode * 110 * Avg Reward is ==> -1682.6289168833214\n",
      "Episode * 111 * Avg Reward is ==> -1682.970997206535\n",
      "Episode * 112 * Avg Reward is ==> -1683.211866729801\n",
      "Episode * 113 * Avg Reward is ==> -1683.2968160134283\n",
      "Episode * 114 * Avg Reward is ==> -1683.38473579845\n",
      "Episode * 115 * Avg Reward is ==> -1682.9216320991786\n",
      "Episode * 116 * Avg Reward is ==> -1683.0925117282748\n",
      "Episode * 117 * Avg Reward is ==> -1683.1274182949926\n",
      "Episode * 118 * Avg Reward is ==> -1682.8892971726666\n",
      "Episode * 119 * Avg Reward is ==> -1683.059261090883\n",
      "Episode * 120 * Avg Reward is ==> -1682.720750890271\n",
      "Episode * 121 * Avg Reward is ==> -1681.293819388102\n",
      "Episode * 122 * Avg Reward is ==> -1681.737848440042\n",
      "Episode * 123 * Avg Reward is ==> -1681.657735167636\n",
      "Episode * 124 * Avg Reward is ==> -1682.1461475152717\n",
      "Episode * 125 * Avg Reward is ==> -1681.7638700368468\n",
      "Episode * 126 * Avg Reward is ==> -1682.5595218911774\n",
      "Episode * 127 * Avg Reward is ==> -1682.4540900498253\n",
      "Episode * 128 * Avg Reward is ==> -1682.4057634736841\n",
      "Episode * 129 * Avg Reward is ==> -1682.456417735766\n",
      "Episode * 130 * Avg Reward is ==> -1682.1123624361942\n",
      "Episode * 131 * Avg Reward is ==> -1681.9703822999834\n",
      "Episode * 132 * Avg Reward is ==> -1681.7131410676852\n",
      "Episode * 133 * Avg Reward is ==> -1681.810830386887\n",
      "Episode * 134 * Avg Reward is ==> -1681.9905858883076\n",
      "Episode * 135 * Avg Reward is ==> -1682.3117024852272\n",
      "Episode * 136 * Avg Reward is ==> -1682.448706323511\n",
      "Episode * 137 * Avg Reward is ==> -1682.6535165442472\n",
      "Episode * 138 * Avg Reward is ==> -1682.7319071092088\n",
      "Episode * 139 * Avg Reward is ==> -1681.9572288423449\n",
      "Episode * 140 * Avg Reward is ==> -1681.8842185185954\n",
      "Episode * 141 * Avg Reward is ==> -1681.3667888505774\n",
      "Episode * 142 * Avg Reward is ==> -1681.4254707745818\n",
      "Episode * 143 * Avg Reward is ==> -1681.7424278059366\n",
      "Episode * 144 * Avg Reward is ==> -1681.8564066976687\n",
      "Episode * 145 * Avg Reward is ==> -1682.4777845334552\n",
      "Episode * 146 * Avg Reward is ==> -1682.6343808627746\n",
      "Episode * 147 * Avg Reward is ==> -1682.6919051881998\n",
      "Episode * 148 * Avg Reward is ==> -1682.6648398698815\n",
      "Episode * 149 * Avg Reward is ==> -1682.8228216881769\n",
      "Episode * 150 * Avg Reward is ==> -1683.2104749203559\n",
      "Episode * 151 * Avg Reward is ==> -1682.9786281995446\n",
      "Episode * 152 * Avg Reward is ==> -1682.8727333350619\n",
      "Episode * 153 * Avg Reward is ==> -1683.295809050145\n",
      "Episode * 154 * Avg Reward is ==> -1683.1214239736312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 155 * Avg Reward is ==> -1682.8613667140307\n",
      "Episode * 156 * Avg Reward is ==> -1682.349015477655\n",
      "Episode * 157 * Avg Reward is ==> -1681.786020708897\n",
      "Episode * 158 * Avg Reward is ==> -1681.5106661734346\n",
      "Episode * 159 * Avg Reward is ==> -1681.3930962277352\n",
      "Episode * 160 * Avg Reward is ==> -1680.862256312641\n",
      "Episode * 161 * Avg Reward is ==> -1680.7688017085363\n",
      "Episode * 162 * Avg Reward is ==> -1680.5690001733847\n",
      "Episode * 163 * Avg Reward is ==> -1680.5102074100664\n",
      "Episode * 164 * Avg Reward is ==> -1680.741561645318\n",
      "Episode * 165 * Avg Reward is ==> -1681.1812026416487\n",
      "Episode * 166 * Avg Reward is ==> -1681.0939254977454\n",
      "Episode * 167 * Avg Reward is ==> -1681.0544930629264\n",
      "Episode * 168 * Avg Reward is ==> -1681.3226600848805\n",
      "Episode * 169 * Avg Reward is ==> -1680.9462900332198\n",
      "Episode * 170 * Avg Reward is ==> -1681.4442575198836\n",
      "Episode * 171 * Avg Reward is ==> -1683.039199237777\n",
      "Episode * 172 * Avg Reward is ==> -1682.8114711495464\n",
      "Episode * 173 * Avg Reward is ==> -1682.8276000491\n",
      "Episode * 174 * Avg Reward is ==> -1682.7444961794588\n",
      "Episode * 175 * Avg Reward is ==> -1683.2878967942731\n",
      "Episode * 176 * Avg Reward is ==> -1682.8762770509604\n",
      "Episode * 177 * Avg Reward is ==> -1682.771983153626\n",
      "Episode * 178 * Avg Reward is ==> -1682.89602236821\n",
      "Episode * 179 * Avg Reward is ==> -1683.3887313137136\n",
      "Episode * 180 * Avg Reward is ==> -1683.538132280462\n",
      "Episode * 181 * Avg Reward is ==> -1683.5741635674176\n",
      "Episode * 182 * Avg Reward is ==> -1683.080505834856\n",
      "Episode * 183 * Avg Reward is ==> -1682.989979689163\n",
      "Episode * 184 * Avg Reward is ==> -1682.6791473722399\n",
      "Episode * 185 * Avg Reward is ==> -1682.728047852081\n",
      "Episode * 186 * Avg Reward is ==> -1682.9130858213002\n",
      "Episode * 187 * Avg Reward is ==> -1682.5343933179581\n",
      "Episode * 188 * Avg Reward is ==> -1682.4366928532068\n",
      "Episode * 189 * Avg Reward is ==> -1682.979797421103\n",
      "Episode * 190 * Avg Reward is ==> -1683.2324478952735\n",
      "Episode * 191 * Avg Reward is ==> -1683.8496208912447\n",
      "Episode * 192 * Avg Reward is ==> -1684.037906704904\n",
      "Episode * 193 * Avg Reward is ==> -1683.7303509687908\n",
      "Episode * 194 * Avg Reward is ==> -1683.746406206873\n",
      "Episode * 195 * Avg Reward is ==> -1683.4129019962777\n",
      "Episode * 196 * Avg Reward is ==> -1682.9405062538501\n",
      "Episode * 197 * Avg Reward is ==> -1682.693053572051\n",
      "Episode * 198 * Avg Reward is ==> -1683.0841991833338\n",
      "Episode * 199 * Avg Reward is ==> -1682.8654887662633\n",
      "Episode * 200 * Avg Reward is ==> -1682.5450874924363\n",
      "Episode * 201 * Avg Reward is ==> -1683.08519836077\n",
      "Episode * 202 * Avg Reward is ==> -1683.1258009900332\n",
      "Episode * 203 * Avg Reward is ==> -1683.2189834520045\n",
      "Episode * 204 * Avg Reward is ==> -1683.6301793218838\n",
      "Episode * 205 * Avg Reward is ==> -1683.5691932650632\n",
      "Episode * 206 * Avg Reward is ==> -1683.83319545177\n",
      "Episode * 207 * Avg Reward is ==> -1684.2066017012812\n",
      "Episode * 208 * Avg Reward is ==> -1684.3864933408934\n",
      "Episode * 209 * Avg Reward is ==> -1684.477262676838\n",
      "Episode * 210 * Avg Reward is ==> -1684.8462879800018\n",
      "Episode * 211 * Avg Reward is ==> -1684.7865919195328\n",
      "Episode * 212 * Avg Reward is ==> -1685.0104378561011\n",
      "Episode * 213 * Avg Reward is ==> -1685.1887724272951\n",
      "Episode * 214 * Avg Reward is ==> -1684.8126117624445\n",
      "Episode * 215 * Avg Reward is ==> -1684.3261662508116\n",
      "Episode * 216 * Avg Reward is ==> -1684.4912466000644\n",
      "Episode * 217 * Avg Reward is ==> -1684.4341504573408\n",
      "Episode * 218 * Avg Reward is ==> -1684.3722718329855\n",
      "Episode * 219 * Avg Reward is ==> -1684.2394546417997\n",
      "Episode * 220 * Avg Reward is ==> -1683.7519316582498\n",
      "Episode * 221 * Avg Reward is ==> -1683.760091412162\n",
      "Episode * 222 * Avg Reward is ==> -1684.0204116223258\n",
      "Episode * 223 * Avg Reward is ==> -1684.0776860788312\n",
      "Episode * 224 * Avg Reward is ==> -1683.992820247165\n",
      "Episode * 225 * Avg Reward is ==> -1683.8272255896777\n",
      "Episode * 226 * Avg Reward is ==> -1683.7230274823041\n",
      "Episode * 227 * Avg Reward is ==> -1683.9410901096167\n",
      "Episode * 228 * Avg Reward is ==> -1684.1615679069128\n",
      "Episode * 229 * Avg Reward is ==> -1684.9402708745858\n",
      "Episode * 230 * Avg Reward is ==> -1685.1267967565823\n",
      "Episode * 231 * Avg Reward is ==> -1685.313916510913\n",
      "Episode * 232 * Avg Reward is ==> -1685.6994414698004\n",
      "Episode * 233 * Avg Reward is ==> -1685.660096093421\n",
      "Episode * 234 * Avg Reward is ==> -1685.8783806579618\n",
      "Episode * 235 * Avg Reward is ==> -1685.956402501606\n",
      "Episode * 236 * Avg Reward is ==> -1686.0589268463239\n",
      "Episode * 237 * Avg Reward is ==> -1685.8812652944482\n",
      "Episode * 238 * Avg Reward is ==> -1685.8915611827795\n",
      "Episode * 239 * Avg Reward is ==> -1685.9922803928814\n",
      "Episode * 240 * Avg Reward is ==> -1686.0759583726606\n",
      "Episode * 241 * Avg Reward is ==> -1685.9012425175702\n",
      "Episode * 242 * Avg Reward is ==> -1685.780231661054\n",
      "Episode * 243 * Avg Reward is ==> -1686.1738393223993\n",
      "Episode * 244 * Avg Reward is ==> -1686.5326271205156\n",
      "Episode * 245 * Avg Reward is ==> -1685.7355119738897\n",
      "Episode * 246 * Avg Reward is ==> -1685.7499421662908\n",
      "Episode * 247 * Avg Reward is ==> -1686.0218024541232\n",
      "Episode * 248 * Avg Reward is ==> -1685.817184774469\n",
      "Episode * 249 * Avg Reward is ==> -1685.971583461104\n",
      "Episode * 250 * Avg Reward is ==> -1685.4390986582457\n",
      "Episode * 251 * Avg Reward is ==> -1685.394550682217\n",
      "Episode * 252 * Avg Reward is ==> -1685.193477347247\n",
      "Episode * 253 * Avg Reward is ==> -1683.8399648619984\n",
      "Episode * 254 * Avg Reward is ==> -1683.3795342139097\n",
      "Episode * 255 * Avg Reward is ==> -1683.3260617627702\n",
      "Episode * 256 * Avg Reward is ==> -1683.060720794321\n",
      "Episode * 257 * Avg Reward is ==> -1682.8665545843508\n",
      "Episode * 258 * Avg Reward is ==> -1682.4561700165964\n",
      "Episode * 259 * Avg Reward is ==> -1682.4247201995602\n",
      "Episode * 260 * Avg Reward is ==> -1682.4391162876905\n",
      "Episode * 261 * Avg Reward is ==> -1682.6796574320679\n",
      "Episode * 262 * Avg Reward is ==> -1681.908703402401\n",
      "Episode * 263 * Avg Reward is ==> -1681.827437733812\n",
      "Episode * 264 * Avg Reward is ==> -1681.8529621666883\n",
      "Episode * 265 * Avg Reward is ==> -1682.2594658003406\n",
      "Episode * 266 * Avg Reward is ==> -1682.1953331851107\n",
      "Episode * 267 * Avg Reward is ==> -1682.1519414010065\n",
      "Episode * 268 * Avg Reward is ==> -1682.1475644894288\n",
      "Episode * 269 * Avg Reward is ==> -1682.4291858020767\n",
      "Episode * 270 * Avg Reward is ==> -1682.7184049408634\n",
      "Episode * 271 * Avg Reward is ==> -1682.7532576297772\n",
      "Episode * 272 * Avg Reward is ==> -1682.7816469974528\n",
      "Episode * 273 * Avg Reward is ==> -1682.6656572489487\n",
      "Episode * 274 * Avg Reward is ==> -1682.7057070099652\n",
      "Episode * 275 * Avg Reward is ==> -1682.4682051574036\n",
      "Episode * 276 * Avg Reward is ==> -1682.768083870496\n",
      "Episode * 277 * Avg Reward is ==> -1683.0331850023022\n",
      "Episode * 278 * Avg Reward is ==> -1682.6645728812891\n",
      "Episode * 279 * Avg Reward is ==> -1682.5106856512489\n",
      "Episode * 280 * Avg Reward is ==> -1682.6287979243466\n",
      "Episode * 281 * Avg Reward is ==> -1682.6391522250833\n",
      "Episode * 282 * Avg Reward is ==> -1683.1277351292667\n",
      "Episode * 283 * Avg Reward is ==> -1683.0821867886425\n",
      "Episode * 284 * Avg Reward is ==> -1682.7455408887163\n",
      "Episode * 285 * Avg Reward is ==> -1682.7096820567056\n",
      "Episode * 286 * Avg Reward is ==> -1682.493678018653\n",
      "Episode * 287 * Avg Reward is ==> -1682.904751945404\n",
      "Episode * 288 * Avg Reward is ==> -1682.8235550228242\n",
      "Episode * 289 * Avg Reward is ==> -1682.8032222628015\n",
      "Episode * 290 * Avg Reward is ==> -1682.449676261829\n",
      "Episode * 291 * Avg Reward is ==> -1681.391842159885\n",
      "Episode * 292 * Avg Reward is ==> -1681.597729806038\n",
      "Episode * 293 * Avg Reward is ==> -1681.6551867415483\n",
      "Episode * 294 * Avg Reward is ==> -1681.4679472555442\n",
      "Episode * 295 * Avg Reward is ==> -1682.2910688213422\n",
      "Episode * 296 * Avg Reward is ==> -1682.4257959390934\n",
      "Episode * 297 * Avg Reward is ==> -1682.094322518369\n",
      "Episode * 298 * Avg Reward is ==> -1681.7554353403445\n",
      "Episode * 299 * Avg Reward is ==> -1681.650187160157\n",
      "Episode * 300 * Avg Reward is ==> -1682.4961666713561\n",
      "Episode * 301 * Avg Reward is ==> -1682.6998815099855\n",
      "Episode * 302 * Avg Reward is ==> -1682.9900730328143\n",
      "Episode * 303 * Avg Reward is ==> -1683.9514575774303\n",
      "Episode * 304 * Avg Reward is ==> -1683.7741373664603\n",
      "Episode * 305 * Avg Reward is ==> -1683.695167126799\n",
      "Episode * 306 * Avg Reward is ==> -1683.7649191216922\n",
      "Episode * 307 * Avg Reward is ==> -1683.7932567434555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 308 * Avg Reward is ==> -1684.284585459397\n",
      "Episode * 309 * Avg Reward is ==> -1683.9727454222964\n",
      "Episode * 310 * Avg Reward is ==> -1683.6625229994956\n",
      "Episode * 311 * Avg Reward is ==> -1683.4738469222978\n",
      "Episode * 312 * Avg Reward is ==> -1684.4132667343208\n",
      "Episode * 313 * Avg Reward is ==> -1684.4834387045066\n",
      "Episode * 314 * Avg Reward is ==> -1684.5514776349646\n",
      "Episode * 315 * Avg Reward is ==> -1684.725930769513\n",
      "Episode * 316 * Avg Reward is ==> -1684.9169506466956\n",
      "Episode * 317 * Avg Reward is ==> -1684.7955584711046\n",
      "Episode * 318 * Avg Reward is ==> -1684.624519967193\n",
      "Episode * 319 * Avg Reward is ==> -1684.652922097529\n",
      "Episode * 320 * Avg Reward is ==> -1684.6130805189023\n",
      "Episode * 321 * Avg Reward is ==> -1684.6910242443396\n",
      "Episode * 322 * Avg Reward is ==> -1684.4329421871596\n",
      "Episode * 323 * Avg Reward is ==> -1684.287608759993\n",
      "Episode * 324 * Avg Reward is ==> -1683.8595146221207\n",
      "Episode * 325 * Avg Reward is ==> -1684.5461547994519\n",
      "Episode * 326 * Avg Reward is ==> -1684.3312309408927\n",
      "Episode * 327 * Avg Reward is ==> -1683.8430375446844\n",
      "Episode * 328 * Avg Reward is ==> -1683.6920965024028\n",
      "Episode * 329 * Avg Reward is ==> -1683.4995630220362\n",
      "Episode * 330 * Avg Reward is ==> -1681.9168062206832\n",
      "Episode * 331 * Avg Reward is ==> -1681.2267774057775\n",
      "Episode * 332 * Avg Reward is ==> -1680.9418053314605\n",
      "Episode * 333 * Avg Reward is ==> -1680.730026411642\n",
      "Episode * 334 * Avg Reward is ==> -1681.2076709379328\n",
      "Episode * 335 * Avg Reward is ==> -1680.983301723899\n",
      "Episode * 336 * Avg Reward is ==> -1680.6993005257987\n",
      "Episode * 337 * Avg Reward is ==> -1680.4821919929243\n",
      "Episode * 338 * Avg Reward is ==> -1680.4123764468977\n",
      "Episode * 339 * Avg Reward is ==> -1680.6557088535224\n",
      "Episode * 340 * Avg Reward is ==> -1680.6742274453409\n",
      "Episode * 341 * Avg Reward is ==> -1681.515205957675\n",
      "Episode * 342 * Avg Reward is ==> -1681.464553728737\n",
      "Episode * 343 * Avg Reward is ==> -1681.2423393399379\n",
      "Episode * 344 * Avg Reward is ==> -1681.2230270212415\n",
      "Episode * 345 * Avg Reward is ==> -1681.4890696746318\n",
      "Episode * 346 * Avg Reward is ==> -1681.438449266424\n",
      "Episode * 347 * Avg Reward is ==> -1681.6197215257419\n",
      "Episode * 348 * Avg Reward is ==> -1681.7661318258763\n",
      "Episode * 349 * Avg Reward is ==> -1681.6934669351508\n",
      "Episode * 350 * Avg Reward is ==> -1681.3866962543088\n",
      "Episode * 351 * Avg Reward is ==> -1681.1142403990382\n",
      "Episode * 352 * Avg Reward is ==> -1681.064140641172\n",
      "Episode * 353 * Avg Reward is ==> -1681.2753663052865\n",
      "Episode * 354 * Avg Reward is ==> -1681.5069957824298\n",
      "Episode * 355 * Avg Reward is ==> -1681.947680897879\n",
      "Episode * 356 * Avg Reward is ==> -1681.9724603700035\n",
      "Episode * 357 * Avg Reward is ==> -1682.1073001791103\n",
      "Episode * 358 * Avg Reward is ==> -1682.1443101536695\n",
      "Episode * 359 * Avg Reward is ==> -1682.2614959157959\n",
      "Episode * 360 * Avg Reward is ==> -1682.6458700092307\n",
      "Episode * 361 * Avg Reward is ==> -1682.4895720770528\n",
      "Episode * 362 * Avg Reward is ==> -1682.1124553349737\n",
      "Episode * 363 * Avg Reward is ==> -1682.0344151453774\n",
      "Episode * 364 * Avg Reward is ==> -1681.8329804613024\n",
      "Episode * 365 * Avg Reward is ==> -1681.7825213117294\n",
      "Episode * 366 * Avg Reward is ==> -1681.465102487481\n",
      "Episode * 367 * Avg Reward is ==> -1681.4108532668913\n",
      "Episode * 368 * Avg Reward is ==> -1681.5299134994257\n",
      "Episode * 369 * Avg Reward is ==> -1681.5102949747243\n",
      "Episode * 370 * Avg Reward is ==> -1681.0950260728198\n",
      "Episode * 371 * Avg Reward is ==> -1680.8134870469473\n",
      "Episode * 372 * Avg Reward is ==> -1681.0695482239287\n",
      "Episode * 373 * Avg Reward is ==> -1681.1126255500546\n",
      "Episode * 374 * Avg Reward is ==> -1681.5695190636895\n",
      "Episode * 375 * Avg Reward is ==> -1681.1308633551118\n",
      "Episode * 376 * Avg Reward is ==> -1681.060312747423\n",
      "Episode * 377 * Avg Reward is ==> -1681.6266517310837\n",
      "Episode * 378 * Avg Reward is ==> -1681.8223488194812\n",
      "Episode * 379 * Avg Reward is ==> -1682.0416936671\n",
      "Episode * 380 * Avg Reward is ==> -1683.6147374971986\n",
      "Episode * 381 * Avg Reward is ==> -1683.4486384717543\n",
      "Episode * 382 * Avg Reward is ==> -1683.4889817650608\n",
      "Episode * 383 * Avg Reward is ==> -1683.733774069938\n",
      "Episode * 384 * Avg Reward is ==> -1683.4929090837236\n",
      "Episode * 385 * Avg Reward is ==> -1683.6039370713981\n",
      "Episode * 386 * Avg Reward is ==> -1683.9188154631292\n",
      "Episode * 387 * Avg Reward is ==> -1684.146191059392\n",
      "Episode * 388 * Avg Reward is ==> -1684.21497779468\n",
      "Episode * 389 * Avg Reward is ==> -1683.8282017989766\n",
      "Episode * 390 * Avg Reward is ==> -1683.5088431520135\n",
      "Episode * 391 * Avg Reward is ==> -1683.5118823659109\n",
      "Episode * 392 * Avg Reward is ==> -1683.3046572313565\n",
      "Episode * 393 * Avg Reward is ==> -1683.1364686425447\n",
      "Episode * 394 * Avg Reward is ==> -1682.6360176285648\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4c661c0007d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mepisodic_reward\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mbuffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mupdate_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_actor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactor_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mupdate_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_critic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-1d57346e6558>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-1d57346e6558>\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, state_batch, action_batch, reward_batch, next_state_batch)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mcritic_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcritic_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mcritic_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritic_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         critic_optimizer.apply_gradients(\n\u001b[0;32m     35\u001b[0m             \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcritic_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py\u001b[0m in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1629\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1630\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1631\u001b[1;33m     \u001b[0mgrad_b\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1632\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mt_a\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mt_b\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1633\u001b[0m     \u001b[0mgrad_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmat_mul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5603\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5604\u001b[0m         \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop_callbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5605\u001b[1;33m         transpose_b)\n\u001b[0m\u001b[0;32m   5606\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ep_reward_list = []\n",
    "\n",
    "avg_reward_list = []\n",
    "\n",
    "\n",
    "for ep in range(total_episodes):\n",
    "\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "\n",
    "    while True:\n",
    "        \n",
    "\n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "    \n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state, action, reward, state))\n",
    "        episodic_reward += reward\n",
    "\n",
    "        buffer.learn()\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prev_state = state\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "    avg_reward = np.mean(ep_reward_list[-50:])\n",
    "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "\n",
    "\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
