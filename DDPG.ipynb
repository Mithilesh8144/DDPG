{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of State Space ->  3\n",
      "Size of Action Space ->  1\n",
      "Max Value of Action ->  2.0\n",
      "Min Value of Action ->  -2.0\n"
     ]
    }
   ],
   "source": [
    "problem = \"Pendulum-v0\"\n",
    "env = gym.make(problem)\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "print(\"Size of State Space ->  {}\".format(num_states))\n",
    "num_actions = env.action_space.shape[0]\n",
    "print(\"Size of Action Space ->  {}\".format(num_actions))\n",
    "\n",
    "upper_bound = env.action_space.high[0]\n",
    "lower_bound = env.action_space.low[0]\n",
    "\n",
    "print(\"Max Value of Action ->  {}\".format(upper_bound))\n",
    "print(\"Min Value of Action ->  {}\".format(lower_bound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OUActionNoise:\n",
    "    def __init__(self, mean, std_deviation, theta=0.15, dt=1e-2, x_initial=None):\n",
    "        self.theta = theta\n",
    "        self.mean = mean\n",
    "        self.std_dev = std_deviation\n",
    "        self.dt = dt\n",
    "        self.x_initial = x_initial\n",
    "        self.reset()\n",
    "\n",
    "    def __call__(self):\n",
    "        # Formula taken from https://www.wikipedia.org/wiki/Ornstein-Uhlenbeck_process.\n",
    "        x = (\n",
    "            self.x_prev\n",
    "            + self.theta * (self.mean - self.x_prev) * self.dt\n",
    "            + self.std_dev * np.sqrt(self.dt) * np.random.normal(size=self.mean.shape)\n",
    "        )\n",
    "        # Store x into x_prev\n",
    "        # Makes next noise dependent on current one\n",
    "        self.x_prev = x\n",
    "        return x\n",
    "\n",
    "    def reset(self):\n",
    "        if self.x_initial is not None:\n",
    "            self.x_prev = self.x_initial\n",
    "        else:\n",
    "            self.x_prev = np.zeros_like(self.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer:\n",
    "    def __init__(self, buffer_capacity=5000, batch_size=64):\n",
    "        self.buffer_capacity = buffer_capacity\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.buffer_counter = 0\n",
    "\n",
    "        self.state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "        self.action_buffer = np.zeros((self.buffer_capacity, num_actions))\n",
    "        self.reward_buffer = np.zeros((self.buffer_capacity, 1))\n",
    "        self.next_state_buffer = np.zeros((self.buffer_capacity, num_states))\n",
    "\n",
    "\n",
    "    def record(self, obs_tuple):\n",
    "        index = self.buffer_counter % self.buffer_capacity\n",
    "\n",
    "        self.state_buffer[index] = obs_tuple[0]\n",
    "        self.action_buffer[index] = obs_tuple[1]\n",
    "        self.reward_buffer[index] = obs_tuple[2]\n",
    "        self.next_state_buffer[index] = obs_tuple[3]\n",
    "\n",
    "        self.buffer_counter += 1\n",
    "\n",
    "    def update(self, state_batch, action_batch, reward_batch, next_state_batch,):\n",
    "        with tf.GradientTape() as tape:\n",
    "            target_actions = target_actor(next_state_batch, training=True)\n",
    "            y = reward_batch + gamma * target_critic(\n",
    "                [next_state_batch, target_actions], training=True\n",
    "            )\n",
    "            critic_value = critic_model([state_batch, action_batch], training=True)\n",
    "            critic_loss = tf.math.reduce_mean(tf.math.square(y - critic_value))\n",
    "\n",
    "        critic_grad = tape.gradient(critic_loss, critic_model.trainable_variables)\n",
    "        critic_optimizer.apply_gradients(\n",
    "            zip(critic_grad, critic_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            actions = actor_model(state_batch, training=True)\n",
    "            critic_value = critic_model([state_batch, actions], training=True)\n",
    "            actor_loss = -tf.math.reduce_mean(critic_value)\n",
    "\n",
    "        actor_grad = tape.gradient(actor_loss, actor_model.trainable_variables)\n",
    "        actor_optimizer.apply_gradients(\n",
    "            zip(actor_grad, actor_model.trainable_variables)\n",
    "        )\n",
    "\n",
    "    def learn(self):\n",
    "\n",
    "        record_range = min(self.buffer_counter, self.buffer_capacity)\n",
    "\n",
    "        batch_indices = np.random.choice(record_range, self.batch_size)\n",
    "\n",
    "        state_batch = tf.convert_to_tensor(self.state_buffer[batch_indices])\n",
    "        action_batch = tf.convert_to_tensor(self.action_buffer[batch_indices])\n",
    "        reward_batch = tf.convert_to_tensor(self.reward_buffer[batch_indices])\n",
    "        reward_batch = tf.cast(reward_batch, dtype=tf.float32)\n",
    "        next_state_batch = tf.convert_to_tensor(self.next_state_buffer[batch_indices])\n",
    "\n",
    "        self.update(state_batch, action_batch, reward_batch, next_state_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def update_target(target_weights, weights, tau):\n",
    "    for (a, b) in zip(target_weights, weights):\n",
    "        a.assign(b * tau + a * (1 - tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_actor():\n",
    "    last_init=tf.random_uniform_initializer(minval=-0.003,maxval=0.003)\n",
    "    i=layers.Input(shape=(num_states))\n",
    "    x=layers.Dense(256,activation='relu')(i)\n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(1,activation='tanh')(x)\n",
    "    x=x*upper_bound\n",
    "    model=tf.keras.Model(i,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor=get_actor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "_________________________________________________________________\n",
      "tf_op_layer_mul (TensorFlowO [(None, 1)]               0         \n",
      "=================================================================\n",
      "Total params: 67,073\n",
      "Trainable params: 67,073\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "actor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_critic():\n",
    "    state_input=layers.Input(shape=(num_states))\n",
    "    state_output=layers.Dense(16,activation='relu')(state_input)\n",
    "    state_output=layers.Dense(32,activation='relu')(state_output)\n",
    "    \n",
    "    action_input=layers.Input(shape=(num_actions))\n",
    "    action_output=layers.Dense(32,activation='relu')(action_input)\n",
    "\n",
    "    concat=layers.Concatenate()([state_output,action_output])\n",
    "    x=layers.Dense(256,activation='relu')(concat)\n",
    "    \n",
    "    x=layers.Dense(256,activation='relu')(x)\n",
    "    x=layers.Dense(1,activation='linear')(x)\n",
    "    model=tf.keras.Model([state_input,action_input],x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "critic=get_critic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           64          input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           544         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           64          input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dense_4[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          16640       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          65792       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            257         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 83,361\n",
      "Trainable params: 83,361\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "critic.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(state, noise_object):\n",
    "    sampled_actions = tf.squeeze(actor_model(state))\n",
    "    noise = noise_object()\n",
    "    sampled_actions = sampled_actions.numpy() + noise\n",
    "\n",
    "    legal_action = np.clip(sampled_actions, lower_bound, upper_bound)\n",
    "\n",
    "    return [np.squeeze(legal_action)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_dev = 0.2\n",
    "ou_noise = OUActionNoise(mean=np.zeros(1), std_deviation=float(std_dev) * np.ones(1))\n",
    "\n",
    "actor_model = get_actor()\n",
    "critic_model = get_critic()\n",
    "\n",
    "target_actor = get_actor()\n",
    "target_critic = get_critic()\n",
    "\n",
    "\n",
    "target_actor.set_weights(actor_model.get_weights())\n",
    "target_critic.set_weights(critic_model.get_weights())\n",
    "\n",
    "\n",
    "critic_lr = 0.002\n",
    "actor_lr = 0.001\n",
    "\n",
    "critic_optimizer = tf.keras.optimizers.Adam(critic_lr)\n",
    "actor_optimizer = tf.keras.optimizers.Adam(actor_lr)\n",
    "\n",
    "total_episodes = 100\n",
    "\n",
    "gamma = 0.99\n",
    "\n",
    "tau = 0.005\n",
    "\n",
    "buffer = Buffer(50000, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode * 0 * Avg Reward is ==> -1367.2224538620555\n",
      "Episode * 1 * Avg Reward is ==> -1453.8342090734259\n",
      "Episode * 2 * Avg Reward is ==> -1492.5891524874178\n",
      "Episode * 3 * Avg Reward is ==> -1462.6139022902496\n",
      "Episode * 4 * Avg Reward is ==> -1460.601045644395\n",
      "Episode * 5 * Avg Reward is ==> -1417.8662489941737\n",
      "Episode * 6 * Avg Reward is ==> -1359.0234179194144\n",
      "Episode * 7 * Avg Reward is ==> -1293.007332920033\n",
      "Episode * 8 * Avg Reward is ==> -1268.6554976735113\n",
      "Episode * 9 * Avg Reward is ==> -1266.8321015167862\n",
      "Episode * 10 * Avg Reward is ==> -1277.3065086331533\n",
      "Episode * 11 * Avg Reward is ==> -1269.752215926871\n",
      "Episode * 12 * Avg Reward is ==> -1229.5496519885933\n",
      "Episode * 13 * Avg Reward is ==> -1185.8404147787899\n",
      "Episode * 14 * Avg Reward is ==> -1163.9571270642457\n",
      "Episode * 15 * Avg Reward is ==> -1107.1969583602981\n",
      "Episode * 16 * Avg Reward is ==> -1078.0704376670421\n",
      "Episode * 17 * Avg Reward is ==> -1038.3555547740652\n",
      "Episode * 18 * Avg Reward is ==> -1046.546894869836\n",
      "Episode * 19 * Avg Reward is ==> -1000.7684213099592\n",
      "Episode * 20 * Avg Reward is ==> -959.126774451062\n",
      "Episode * 21 * Avg Reward is ==> -927.1731041870692\n",
      "Episode * 22 * Avg Reward is ==> -892.4186874600721\n",
      "Episode * 23 * Avg Reward is ==> -860.4596533056374\n",
      "Episode * 24 * Avg Reward is ==> -826.0809299161274\n",
      "Episode * 25 * Avg Reward is ==> -808.2720964300032\n",
      "Episode * 26 * Avg Reward is ==> -782.8289628231992\n",
      "Episode * 27 * Avg Reward is ==> -759.3202933991901\n",
      "Episode * 28 * Avg Reward is ==> -741.3234113897661\n",
      "Episode * 29 * Avg Reward is ==> -728.8372891868021\n",
      "Episode * 30 * Avg Reward is ==> -705.3534445933211\n",
      "Episode * 31 * Avg Reward is ==> -690.1874276675147\n",
      "Episode * 32 * Avg Reward is ==> -694.3767907385632\n",
      "Episode * 33 * Avg Reward is ==> -695.8063671365633\n",
      "Episode * 34 * Avg Reward is ==> -693.4306562283257\n",
      "Episode * 35 * Avg Reward is ==> -691.8497498491972\n",
      "Episode * 36 * Avg Reward is ==> -690.1278306522655\n",
      "Episode * 37 * Avg Reward is ==> -686.5112557472015\n",
      "Episode * 38 * Avg Reward is ==> -681.2592434022699\n",
      "Episode * 39 * Avg Reward is ==> -667.4663564255751\n",
      "Episode * 40 * Avg Reward is ==> -633.428449608173\n",
      "Episode * 41 * Avg Reward is ==> -598.0179358613875\n",
      "Episode * 42 * Avg Reward is ==> -561.7539590125509\n",
      "Episode * 43 * Avg Reward is ==> -533.1792423178489\n",
      "Episode * 44 * Avg Reward is ==> -499.9020162534862\n",
      "Episode * 45 * Avg Reward is ==> -472.9545876773198\n",
      "Episode * 46 * Avg Reward is ==> -463.5556104489862\n",
      "Episode * 47 * Avg Reward is ==> -442.86864555825844\n",
      "Episode * 48 * Avg Reward is ==> -421.85684194695585\n",
      "Episode * 49 * Avg Reward is ==> -396.97954762837475\n",
      "Episode * 50 * Avg Reward is ==> -368.76124674088055\n",
      "Episode * 51 * Avg Reward is ==> -342.1196854427044\n",
      "Episode * 52 * Avg Reward is ==> -326.4877506227197\n",
      "Episode * 53 * Avg Reward is ==> -314.1595390480055\n",
      "Episode * 54 * Avg Reward is ==> -299.00290683054675\n",
      "Episode * 55 * Avg Reward is ==> -306.038979160311\n",
      "Episode * 56 * Avg Reward is ==> -297.075224910296\n",
      "Episode * 57 * Avg Reward is ==> -291.00282512377737\n",
      "Episode * 58 * Avg Reward is ==> -264.1747018083609\n",
      "Episode * 59 * Avg Reward is ==> -263.95016192063173\n",
      "Episode * 60 * Avg Reward is ==> -270.01109219560055\n",
      "Episode * 61 * Avg Reward is ==> -266.8291349148457\n",
      "Episode * 62 * Avg Reward is ==> -272.20099518611005\n",
      "Episode * 63 * Avg Reward is ==> -277.85744920791876\n",
      "Episode * 64 * Avg Reward is ==> -280.88432020880833\n",
      "Episode * 65 * Avg Reward is ==> -274.8960791757694\n",
      "Episode * 66 * Avg Reward is ==> -281.64425948659095\n",
      "Episode * 67 * Avg Reward is ==> -281.5490412761075\n",
      "Episode * 68 * Avg Reward is ==> -281.707753289828\n",
      "Episode * 69 * Avg Reward is ==> -275.838521264925\n",
      "Episode * 70 * Avg Reward is ==> -278.7042767849907\n",
      "Episode * 71 * Avg Reward is ==> -276.39791799286127\n",
      "Episode * 72 * Avg Reward is ==> -258.64704605468523\n",
      "Episode * 73 * Avg Reward is ==> -240.17785083474274\n",
      "Episode * 74 * Avg Reward is ==> -227.84715198989653\n",
      "Episode * 75 * Avg Reward is ==> -220.12431544238848\n",
      "Episode * 76 * Avg Reward is ==> -213.36789278376432\n",
      "Episode * 77 * Avg Reward is ==> -205.8220879809134\n",
      "Episode * 78 * Avg Reward is ==> -196.93855304990586\n",
      "Episode * 79 * Avg Reward is ==> -196.811093511643\n",
      "Episode * 80 * Avg Reward is ==> -218.76964751934656\n",
      "Episode * 81 * Avg Reward is ==> -221.59372928553654\n",
      "Episode * 82 * Avg Reward is ==> -227.92698177364863\n",
      "Episode * 83 * Avg Reward is ==> -241.1059112636517\n",
      "Episode * 84 * Avg Reward is ==> -244.11349025723052\n",
      "Episode * 85 * Avg Reward is ==> -246.838230818082\n",
      "Episode * 86 * Avg Reward is ==> -236.75789142613317\n",
      "Episode * 87 * Avg Reward is ==> -242.46248750160984\n",
      "Episode * 88 * Avg Reward is ==> -239.77435656564202\n",
      "Episode * 89 * Avg Reward is ==> -239.03085575370233\n",
      "Episode * 90 * Avg Reward is ==> -235.97658766962076\n",
      "Episode * 91 * Avg Reward is ==> -235.96822234794777\n",
      "Episode * 92 * Avg Reward is ==> -235.92421918237227\n",
      "Episode * 93 * Avg Reward is ==> -235.9866946767339\n",
      "Episode * 94 * Avg Reward is ==> -232.9078231617963\n",
      "Episode * 95 * Avg Reward is ==> -222.55292365294818\n",
      "Episode * 96 * Avg Reward is ==> -219.28753967004022\n",
      "Episode * 97 * Avg Reward is ==> -222.70574735817982\n",
      "Episode * 98 * Avg Reward is ==> -222.88763521707742\n",
      "Episode * 99 * Avg Reward is ==> -225.91195022312286\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ep_reward_list = []\n",
    "\n",
    "avg_reward_list = []\n",
    "\n",
    "for ep in range(total_episodes):\n",
    "\n",
    "    prev_state = env.reset()\n",
    "    episodic_reward = 0\n",
    "\n",
    "    while True:\n",
    "   \n",
    "        tf_prev_state = tf.expand_dims(tf.convert_to_tensor(prev_state), 0)\n",
    "\n",
    "        action = policy(tf_prev_state, ou_noise)\n",
    "\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        buffer.record((prev_state, action, reward, state))\n",
    "        episodic_reward += reward\n",
    "\n",
    "        buffer.learn()\n",
    "        update_target(target_actor.variables, actor_model.variables, tau)\n",
    "        update_target(target_critic.variables, critic_model.variables, tau)\n",
    "\n",
    "       \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        prev_state = state\n",
    "\n",
    "    ep_reward_list.append(episodic_reward)\n",
    "\n",
    "\n",
    "    avg_reward = np.mean(ep_reward_list[-40:])\n",
    "    print(\"Episode * {} * Avg Reward is ==> {}\".format(ep, avg_reward))\n",
    "    avg_reward_list.append(avg_reward)\n",
    "\n",
    "\n",
    "plt.plot(avg_reward_list)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Avg. Epsiodic Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensorflow] *",
   "language": "python",
   "name": "conda-env-.conda-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
